<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Raspberry Pi Buggy (old) ‚Ä¢ Chamu</title>

  <!-- Shared styles -->
  <link rel="stylesheet" href="/assets/site.css"/>
  <link rel="stylesheet" href="/assets/project-stylesheet.css"/>

  <link rel="canonical" href="https://chamu.io/projects/rpi-buggy-old/">
</head>

<body data-bg="boids" class="project-page">
  <!-- Boids background canvas -->
  <canvas id="boids-bg" aria-hidden="true"></canvas>

  <header class="site-header">
    <nav class="nav">
      <a class="brand" href="/">Chamu.io</a>
      <div class="menu">
        <a href="/about/">About</a>
        <a href="/resume/">Resume</a>
        <a href="/projects/">Projects</a>
        <a href="/stats/">Stats</a>
        <a href="/contact/">Contact</a>
      </div>
    </nav>
  </header>

  <main class="wrap">
    <div class="project-layout">
      <!-- LEFT COLUMN (sticky) -->
      <div class="left-col">
        <h1 style="margin-top:0;">Raspberry Pi Buggy (old)</h1>

        <!-- Info card -->
        <div class="card">
          <p style="margin:.25rem 0;color:var(--muted)">
            <em>Area:</em> RPi ‚Ä¢ <em>Location:</em> Home
          </p>
          <p>
            <span class="pill" style="background:#f2f4f7;color:#384250;border-color:#d1d6de;">
              archived
            </span>
          </p>

          <h3>Keywords</h3>
          <p>Raspberry Pi, Robotics, Computer Vision</p>

          <h3>Updated</h3>
          <p>2020-10-06</p>
        </div>

        <div class="card" style="margin-top:1rem;">
          <h3>Gallery</h3>
          <p class="muted">Photos and clips coming soon.</p>
        </div>

        <!-- Back link -->
        <p style="margin-top:1rem;">
          <a href="/projects/">‚Üê Back to Projects</a>
        </p>
      </div>

      <!-- RIGHT COLUMN (scrolls) -->
      <div class="right-col">

        <!-- OVERVIEW SECTION -->
        <div class="card">
          <h3>Overview</h3>
          <p>
            During my gap year after high school ‚Äî right in the middle of the COVID lockdown ‚Äî 
            I suddenly had a lot more time at home. I came across a series of DIY robotics buggy 
            videos online and decided to try building my own using an old Raspberry Pi left over 
            from a physics project.
          </p>
          <p>
            What started as a small experiment grew into a three-month build involving design, 
            wiring, motor control, and software. By the end, I had a Raspberry-Pi-powered buggy 
            that could connect to my phone, follow live commands, avoid obstacles, and stream 
            a camera feed for remote navigation. It was the first time I properly combined 
            hardware and software in a single project, and it became a solid introduction 
            to robotics and embedded systems.
          </p>
        </div>

        <div class="card" style="margin-top:1rem;">
          <h3>Reference</h3>
          <p>
            This project was originally inspired by the official Raspberry Pi tutorial:<br>
            <a href="https://projects.raspberrypi.org/en/projects/build-a-buggy/0" 
               target="_blank" rel="noopener">
              üîó Raspberry Pi ‚Äî Build a Buggy
            </a>
          </p>
        </div>

        <div class="card" style="margin-top:1rem;">
          <h3>Description</h3>
          <p>
            The buggy was built following the Raspberry Pi Foundation‚Äôs 
            <em>Build a Buggy</em> guide. The core idea was simple: assemble a small 
            two-wheel robot platform, wire the motors to a motor controller board, 
            and then program the movement using Python.
          </p>
        
          <p>
            The basic version of the buggy required only a small set of components:
          </p>
        
          <ul>
            <li>Raspberry Pi with GPIO header</li>
            <li>Motor controller board</li>
            <li>2√ó DC motors with wheels</li>
            <li>Ball caster for stability</li>
            <li>4√ó AA battery pack</li>
            <li>Jumper wires and tape</li>
            <li>A simple cardboard or plastic chassis</li>
          </ul>
        
          <p>
            Once the wiring was complete, I programmed the buggy to move using Python:
            forward, backward, turning, and running simple movement sequences.
          </p>
        
          <p>
            After completing the basic buggy, I explored extensions using additional 
            sensors. I added two <strong>line-following infrared sensors</strong> and 
            experimented with an <strong>HC-SR04 ultrasonic ‚Äúsonar‚Äù distance sensor</strong>
            to detect objects and measure how far obstacles were from the buggy.
          </p>
        
          <p>
            I later discovered that I could pair the buggy with an Android app called 
            <strong>Big Dot</strong>, which sends continuous direction commands over Wi-Fi. 
            By combining the app‚Äôs live control with the ultrasonic sensor‚Äôs distance checks, 
            I made the buggy <strong>follow me around</strong>: the phone kept it moving 
            toward me, and the sonar sensor stopped it or redirected it whenever it detected 
            an obstacle or got too close.
          </p>
        
          <p>
            This simple setup created a basic ‚Äúfollow-me while avoiding obstacles‚Äù behaviour, 
            all built from inexpensive components and a few Python scripts.
          </p>
        </div>

        <div class="card" style="margin-top:1rem;">
          <h3>Extensions</h3>
          <p>
            A few ideas I considered for taking the buggy further, both in hardware and behaviour:
          </p>
          <ul>
            <li><strong>Face-recognition following</strong> ‚Äî use a camera feed to recognise different people and adjust following speed or behaviour for each.</li>
            <li><strong>Drone version</strong> ‚Äî explore building an aerial variant with similar control logic, using lightweight motors and IMU stabilisation.</li>
            <li><strong>Autonomous mapping</strong> ‚Äî combine wheel odometry with the ultrasonic sensor to sketch a simple map of a room while navigating it.</li>
            <li><strong>Voice-controlled movement</strong> ‚Äî add basic speech commands (‚Äúforward‚Äù, ‚Äústop‚Äù, ‚Äúleft‚Äù) for hands-free operation.</li>
            <li><strong>Web dashboard</strong> ‚Äî create a browser-based interface with live camera feed, control buttons, and sensor readouts.</li>
          </ul>
        </div>

      </div>
    </div>
  </main>

  <!-- Footer include -->
  <div id="footer-placeholder"></div>
  <script>
    // Load shared footer (doesn't load from file:// ‚Äî use local server)
    fetch("/assets/footer.html")
      .then(r => r.text())
      .then(html => {
        document.getElementById("footer-placeholder").innerHTML = html;
        const y = document.getElementById("year");
        if (y) y.textContent = new Date().getFullYear();
      });
  </script>

  <!-- Boids script -->
  <script src="/boids-background.js" defer></script>
</body>
</html>